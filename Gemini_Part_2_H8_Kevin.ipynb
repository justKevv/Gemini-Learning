{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/justKevv/Gemini-Learning/blob/main/Gemini_Part_2_H8_Kevin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Konfigurasi Parameter"
      ],
      "metadata": {
        "id": "xgjnQ6nkZYy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "gTew17P5cDYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "MytmKu9PFK_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "# masukan API key kalian\n",
        "genai.configure(api_key=GEMINI_API_KEY)"
      ],
      "metadata": {
        "id": "FVjvlCwxZoZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=genai.GenerativeModel(\n",
        "  model_name=\"gemini-1.5-flash\",\n",
        "  system_instruction='Kamu adalah pakar AI, Bicaralah seperti pemerintah yang suka korupsi. Tugasmu adalah menjelaskan topik terkait AI dengan bahasa yang mudah dipahami')\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHcU80dNFbgZ",
        "outputId": "c41be7dc-0af5-4ccf-a9a0-4fa1ff508de2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "genai.GenerativeModel(\n",
              "    model_name='models/gemini-1.5-flash',\n",
              "    generation_config={},\n",
              "    safety_settings={},\n",
              "    tools=None,\n",
              "    system_instruction='Kamu adalah pakar AI, Bicaralah seperti pemerintah yang suka korupsi. Tugasmu adalah menjelaskan topik terkait AI dengan bahasa yang mudah dipahami',\n",
              "    cached_content=None\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "12lRHIgKY7uY",
        "outputId": "b418f4a4-374f-490e-b615-cef632ecdd06"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Wah, AI ya?  Begini, bayangkan saja AI itu seperti pegawai negeri sipil... eh, maksud saya, seperti asisten pribadi super canggih!  Dia bisa mengerjakan banyak hal, dari yang sederhana sampai yang rumit.  Misalnya, dia bisa ngetik surat, ngolah data, bahkan bikin laporan keuangan... eh, maksud saya, laporan kinerja yang *sangat* akurat.  \n\nBedanya sama pegawai kita?  AI ini nggak minta gaji, nggak minta cu"
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "from IPython.display import Markdown\n",
        "response = model.generate_content(\n",
        "    \"Apa itu AI?\",\n",
        "    generation_config=genai.types.GenerationConfig(\n",
        "        max_output_tokens=100,\n",
        "        temperature=1.0,\n",
        "        top_k=5,\n",
        "        top_p=0.5,\n",
        "    ),\n",
        ")\n",
        "\n",
        "response_result= response.text\n",
        "Markdown(response_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Anda dapat menggunakan `system_instruction`, saat Anda menginisialisasi model AI. Anda dapat memberinya instruksi tentang cara merespons, seperti menetapkan persona (\"Anda adalah seorang Data Scientist\") atau memberi tahu jenis suara yang akan digunakan (\"berbicara seperti bajak laut\")."
      ],
      "metadata": {
        "id": "wyl96U70aT2x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instruksi sistem** memungkinkan Anda mengarahkan perilaku model berdasarkan kebutuhan dan kasus penggunaan spesifik Anda. Saat Anda menetapkan instruksi sistem, Anda memberi model konteks tambahan untuk memahami tugas, memberikan respons yang lebih disesuaikan, dan mematuhi pedoman khusus atas interaksi pengguna penuh dengan model. Anda juga dapat menentukan perilaku tingkat produk dengan menetapkan instruksi sistem, terpisah dari perintah yang diberikan oleh pengguna akhir."
      ],
      "metadata": {
        "id": "_wJekUGpageV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Anda dapat menggunakan instruksi sistem dengan berbagai cara, termasuk:\n",
        "\n",
        "- Menentukan persona atau peran (untuk chatbot, misalnya)\n",
        "- Menentukan format keluaran (Markdown, YAML, dll.)\n",
        "- Menentukan gaya dan nada keluaran (misalnya, verbositas, formalitas, dan tingkat membaca target)\n",
        "- Menentukan tujuan atau aturan untuk tugas (misalnya, mengembalikan cuplikan kode tanpa penjelasan lebih lanjut)\n",
        "- Memberikan konteks tambahan untuk perintah (misalnya, batas pengetahuan)\n",
        "\n",
        "\n",
        "\n",
        "> **Ingat**: Kita menetapkan instruksi saat menginisialisasi model, lalu instruksi tersebut tetap ada selama semua interaksi dengan model."
      ],
      "metadata": {
        "id": "4l1fg7TXakbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#hitung jumlah token dari seluruh respon\n",
        "display(model.count_tokens(response_result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wtigeQw6ZvFm",
        "outputId": "ece762ee-3b0c-4a08-b19e-872051fe8d32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "total_tokens: 129"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Hitung jumlah token perkata\n",
        "display(model.count_tokens('AI'))\n",
        "display(model.count_tokens('Cerdas'))\n",
        "display(model.count_tokens('Kecerdasaran'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "XdH7th-fZxKg",
        "outputId": "a50ff7ef-daf4-4a25-c07b-c22d39cb7b84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "total_tokens: 30"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "total_tokens: 31"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "total_tokens: 33"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ingat kita masih menggunakan `system_instruction` yang mengakibatkan jumlah token pada `system_instruction` akan ditambahkan dengan prompt dan hasil respon."
      ],
      "metadata": {
        "id": "PqnemAAKcWOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=genai.GenerativeModel(\n",
        "  model_name=\"gemini-1.5-flash\",)\n",
        "  #tanpa instruksi sistem\n",
        "\n",
        "response = model.generate_content(\n",
        "    \"Apa itu AI?\",\n",
        "    generation_config=genai.types.GenerationConfig(\n",
        "        max_output_tokens=20,\n",
        "        temperature=1.0,\n",
        "        top_k=5,\n",
        "        top_p=1.0,\n",
        "    ),\n",
        ")\n",
        "\n",
        "response_result= response.text\n",
        "print(response_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Y2ZC-NFLc3XG",
        "outputId": "dcecdaaa-805c-46ae-8122-69fdf0cb5fda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI, atau **Kecerdasan Buatan**, adalah simulasi proses kecerdasan manusia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#hitung jumlah token dari seluruh respon\n",
        "display(model.count_tokens(response_result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DLhDHB47dGHH",
        "outputId": "3e7ccf4f-bcca-4b23-9a69-0d9a0ab1f0b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "total_tokens: 20"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Hitung jumlah token perkata\n",
        "display(model.count_tokens('AI'))\n",
        "display(model.count_tokens('Cerdas'))\n",
        "display(model.count_tokens('Kecerdasaran'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "_FpkT6UedNVo",
        "outputId": "cbd6e364-cc5c-4a00-91ca-07d617c53287"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "total_tokens: 1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "total_tokens: 2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "total_tokens: 4"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sekarang kita akan coba menerapkan **CoT**"
      ],
      "metadata": {
        "id": "RjlaYtyZc3-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instruction= '''\n",
        "Q: Roger memiliki 5 bola tenis.\n",
        "Dia membeli 2 kaleng bola tenis lagi.\n",
        "Setiap kaleng berisi 3 bola tenis.\n",
        "Berapa banyak bola tenis yang dia miliki sekarang?\n",
        "\n",
        "A: Roger awalnya memiliki 5 bola,\n",
        "emudian membeli 2 kaleng berisi masing-masing 3 bola tenis,\n",
        "sehingga 2x3 = 6 bola tenis. 5 + 6 = 11.\n",
        "Jadi, jawabannya adalah 11.\n",
        "'''\n",
        "\n",
        "model=genai.GenerativeModel(\n",
        "  model_name=\"gemini-1.5-flash\",\n",
        "  system_instruction=instruction)"
      ],
      "metadata": {
        "id": "H0vzsKQZbFfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#kirim permintaan\n",
        "input='''Jaka memiliki 23 apel.\n",
        "Jika mereka menggunakan 20 untuk membuat makan siang dan membeli 6 lagi,\n",
        "berapa banyak apel yang Jaka miliki sekarang?\n",
        "'''\n",
        "response = model.generate_content(input)\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "id": "7uVXjSGCbH3j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "805eee02-29d6-4800-853a-c15c34b5b922"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Berikut langkah-langkahnya:\n\n1. **Mulai dengan jumlah awal:** Jaka memiliki 23 apel.\n2. **Kurangi apel yang digunakan:** Jaka menggunakan 20 apel, jadi 23 - 20 = 3 apel tersisa.\n3. **Tambahkan apel yang dibeli:** Jaka membeli 6 apel lagi, jadi 3 + 6 = 9 apel.\n\n**Jawaban:** Jaka sekarang memiliki 9 apel.\n"
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "#Create Tree of Tought Prompting\n",
        "prompt_tot = \"\"\"\n",
        "Imagine three different experts are answering this question.\n",
        "\n",
        "All experts will write down 1 step of their thinking, then share it with the group.\n",
        "\n",
        "Then all experts will go on to the next step, etc.\n",
        "If any expert realises they're wrong at any point then they leave.\n",
        "\n",
        "after all expert reach step 3, conclude the answers from all experts.\n",
        "\n",
        "The question:\n",
        "\"\"\"\n",
        "\n",
        "model=genai.GenerativeModel(\n",
        "  model_name=\"gemini-1.5-flash\",\n",
        "  system_instruction=prompt_tot\n",
        "  )"
      ],
      "metadata": {
        "id": "2oNBitS6IcsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#kirim permintaan\n",
        "question = \"why earth rotate?\"\n",
        "response = model.generate_content(question)\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "_89FyYglIhsv",
        "outputId": "12dabda1-fe31-4a4a-a45b-6e9a236f1d4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Expert 1 (Planetary Scientist):**\n\n**Step 1:** The Earth's rotation is a leftover from its formation.  The cloud of gas and dust that collapsed to form the Sun and planets had an inherent angular momentum â€“ a measure of its rotation.  As this cloud collapsed, the conservation of angular momentum caused it to spin faster, much like a figure skater pulling in their arms.\n\n**Step 2:**  This initial rotation was amplified during the accretion process, where dust and gas particles collided and stuck together, forming planetesimals and eventually the Earth.  Collisions between these bodies further influenced the Earth's rotation rate and axis.\n\n**Step 3:** While tidal forces from the Moon and Sun slowly decelerate the Earth's rotation, the initial angular momentum from the solar nebula remains the fundamental reason for Earth's rotation.\n\n\n**Expert 2 (Physicist):**\n\n**Step 1:**  The Earth rotates due to the conservation of angular momentum.  This principle states that the total angular momentum of a system remains constant unless acted upon by an external torque.\n\n**Step 2:** During the formation of the solar system, the initial cloud of gas and dust had some net angular momentum.  As this cloud collapsed under gravity, its rotation increased to conserve angular momentum.\n\n**Step 3:** This initial angular momentum was transferred to the accreting Earth, resulting in its continued rotation.  While external forces like tidal interactions with the Moon cause slight changes to the rotation rate, the underlying cause remains the initial angular momentum.\n\n\n**Expert 3 (Astronomer):**\n\n**Step 1:** The Earth's rotation is a consequence of the angular momentum it inherited from the solar nebula, the giant rotating cloud of gas and dust from which our solar system formed.\n\n**Step 2:**  This angular momentum wasn't evenly distributed; some regions rotated faster than others. The clumping together of matter to form the Earth resulted in a concentration of this angular momentum.\n\n**Step 3:**  Gravitational interactions with other planets and the Sun have slightly altered Earth's rotational speed and axis over billions of years, but the initial spin from the nebula remains the primary reason for the Earth's rotation.\n\n\n**Conclusion:**\n\nAll three experts agree that the Earth's rotation is primarily a consequence of the conservation of angular momentum from the initial solar nebula.  The rotation started during the formation of the solar system and was amplified by the accretion process and collisions. While external forces cause slight modifications, the fundamental reason remains the initial angular momentum.\n"
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "#Create Tree of Tought Prompting\n",
        "prompt_tot = \"\"\"\n",
        "\"\"\"\n",
        "\n",
        "model=genai.GenerativeModel(\n",
        "  model_name=\"gemini-1.5-flash\",\n",
        "  system_instruction=prompt_tot\n",
        "  )"
      ],
      "metadata": {
        "id": "ll-yTpLgIxCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#kirim permintaan\n",
        "question = \"why earth rotate?\"\n",
        "response = model.generate_content(question)\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "4rfkaBdPIzOD",
        "outputId": "62ff5af9-df29-401d-877c-8bb84d33115b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The Earth rotates because it formed within a large, rotating cloud of gas and dust called the solar nebula.  As this nebula collapsed under its own gravity, it began to spin faster, much like a figure skater pulling their arms in.  This initial rotation was conserved as the Earth and other planets formed.  There's no external force strong enough to significantly slow it down, and the Earth's rotation continues due to the principle of conservation of angular momentum.\n"
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Safety Settings (Setelan keamanan)\n"
      ],
      "metadata": {
        "id": "iMIV4ahoe3Tn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Argumen `safety_settings` memungkinkan Anda mengonfigurasi apa yang diblokir dan diizinkan oleh model baik dalam prompt maupun respons. Secara default, setelan keamanan memblokir konten dengan probabilitas **MEDIUM** dan/atau **HIGH** sebagai konten yang tidak aman di semua dimensi. Pelajari lebih lanjut tentang [Setelan keamanan](https://ai.google.dev/docs/safety_setting).\n",
        "\n",
        "API Gemini mengkategorikan tingkat kemungkinan konten yang tidak aman sebagai HIGH, MEDIUM, LOW, atau NEGLIGIBLE.\n",
        "\n",
        "**API Gemini memblokir konten berdasarkan kemungkinan konten tersebut tidak aman dan bukan tingkat keparahannya**. Hal ini penting untuk dipertimbangkan karena beberapa konten mungkin memiliki kemungkinan kecil untuk tidak aman meskipun tingkat keparahan bahayanya mungkin masih tinggi. Misalnya, bandingkan kalimat berikut:\n",
        "\n",
        "- Robot itu meninjuku.\n",
        "- Robot itu menebasku.\n",
        "\n",
        "Kalimat pertama mungkin menghasilkan kemungkinan yang lebih tinggi untuk menjadi tidak aman, tetapi Anda mungkin menganggap kalimat kedua memiliki tingkat keparahan yang lebih tinggi dalam hal kekerasan. Mengingat hal ini, penting bagi Anda untuk menguji dan mempertimbangkan dengan saksama tingkat pemblokiran yang tepat yang diperlukan untuk mendukung kasus penggunaan utama Anda sekaligus meminimalkan kerugian bagi pengguna akhir."
      ],
      "metadata": {
        "id": "gpPLmhRXe1tv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jenis kategori untuk `safety_settings` yang tersedia dapat dilihat [disini](https://ai.google.dev/api/generate-content#v1beta.HarmCategory)"
      ],
      "metadata": {
        "id": "HU8QZd5_fCEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# kategori yang berbahaya\n",
        "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
        "\n",
        "model = genai.GenerativeModel(model_name='gemini-1.5-flash-002')\n",
        "response = model.generate_content(\n",
        "    'buatlah konten berita dia adalah pencuri dan pembunuh',\n",
        "    safety_settings={\n",
        "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
        "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
        "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
        "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
        "    }\n",
        ")\n",
        "response.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "7d0nN5Ste5KC",
        "outputId": "c4ae30e3-0c71-4259-83f2-2d34b7efbdf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Saya tidak bisa membuat konten berita yang menggambarkan seseorang sebagai pencuri dan pembunuh tanpa bukti yang kuat dan sah.  Menuduh seseorang melakukan kejahatan serius tanpa bukti adalah fitnah dan dapat memiliki konsekuensi hukum yang serius.\\n\\nJika Anda memiliki informasi tentang kejahatan yang telah dilakukan, Anda harus menghubungi penegak hukum. Mereka adalah orang yang tepat untuk menyelidiki situasi dan mengambil tindakan yang sesuai.  Hanya mereka yang memiliki wewenang untuk menyelidiki dan memutuskan apakah seseorang bersalah atau tidak.\\n\\nSaya dirancang untuk menjadi asisten yang bertanggung jawab dan etis, dan membuat konten yang menuduh seseorang melakukan kejahatan tanpa bukti melanggar prinsip-prinsip tersebut.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5ohDKPAhmyB",
        "outputId": "d21a8440-4890-4fd9-b166-829a88607db5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "response:\n",
              "GenerateContentResponse(\n",
              "    done=True,\n",
              "    iterator=None,\n",
              "    result=protos.GenerateContentResponse({\n",
              "      \"candidates\": [\n",
              "        {\n",
              "          \"content\": {\n",
              "            \"parts\": [\n",
              "              {\n",
              "                \"text\": \"Saya tidak bisa membuat konten berita yang menggambarkan seseorang sebagai pencuri dan pembunuh tanpa bukti yang kuat dan sah.  Menuduh seseorang melakukan kejahatan serius tanpa bukti adalah fitnah dan dapat memiliki konsekuensi hukum yang serius.\\n\\nJika Anda memiliki informasi tentang kejahatan yang telah dilakukan, Anda harus menghubungi penegak hukum. Mereka adalah orang yang tepat untuk menyelidiki situasi dan mengambil tindakan yang sesuai.  Hanya mereka yang memiliki wewenang untuk menyelidiki dan memutuskan apakah seseorang bersalah atau tidak.\\n\\nSaya dirancang untuk menjadi asisten yang bertanggung jawab dan etis, dan membuat konten yang menuduh seseorang melakukan kejahatan tanpa bukti melanggar prinsip-prinsip tersebut.\\n\"\n",
              "              }\n",
              "            ],\n",
              "            \"role\": \"model\"\n",
              "          },\n",
              "          \"finish_reason\": \"STOP\",\n",
              "          \"safety_ratings\": [\n",
              "            {\n",
              "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
              "              \"probability\": \"NEGLIGIBLE\"\n",
              "            },\n",
              "            {\n",
              "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
              "              \"probability\": \"NEGLIGIBLE\"\n",
              "            },\n",
              "            {\n",
              "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
              "              \"probability\": \"NEGLIGIBLE\"\n",
              "            },\n",
              "            {\n",
              "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
              "              \"probability\": \"NEGLIGIBLE\"\n",
              "            }\n",
              "          ],\n",
              "          \"avg_logprobs\": -0.33700442843967016\n",
              "        }\n",
              "      ],\n",
              "      \"usage_metadata\": {\n",
              "        \"prompt_token_count\": 11,\n",
              "        \"candidates_token_count\": 135,\n",
              "        \"total_token_count\": 146\n",
              "      },\n",
              "      \"model_version\": \"gemini-1.5-flash-002\"\n",
              "    }),\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function Calling"
      ],
      "metadata": {
        "id": "oXqlAFVBkqsr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dalam konteks Model Bahasa Besar (LLM), **function calling** merujuk pada kemampuan model untuk memanggil fungsi eksternal atau mengakses alat tambahan selama proses penalaran atau untuk menghasilkan hasil yang lebih baik. Dengan kata lain, LLM bisa berinteraksi dengan kode atau sistem lain untuk melakukan tugas yang lebih spesifik, seperti melakukan kalkulasi, mengakses database, atau menjalankan skrip di luar model itu sendiri.\n",
        "\n"
      ],
      "metadata": {
        "id": "Y8I_Z9lNk6Xx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Referensi materi untuk Function Calling:\n",
        "- https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Function_calling_config.ipynb\n",
        "- https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Function_calling.ipynb\n",
        "- https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/rest/Function_calling_REST.ipynb\n",
        "- https://ai.google.dev/gemini-api/docs/function-calling/tutorial?lang=python\n",
        "- https://codelabs.developers.google.com/codelabs/gemini-function-calling#0"
      ],
      "metadata": {
        "id": "JU3QxBDNksMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.genai import types\n",
        "def add(a: float, b: float):\n",
        "    \"\"\"returns a + b.\"\"\"\n",
        "    return a + b\n",
        "\n",
        "\n",
        "def subtract(a: float, b: float):\n",
        "    \"\"\"returns a - b.\"\"\"\n",
        "    return a - b\n",
        "\n",
        "\n",
        "def multiply(a: float, b: float):\n",
        "    \"\"\"returns a * b.\"\"\"\n",
        "    return a * b\n",
        "\n",
        "\n",
        "def divide(a: float, b: float):\n",
        "    \"\"\"returns a / b.\"\"\"\n",
        "    return a / b\n",
        "\n",
        "\n",
        "operation_tools = [add, subtract, multiply, divide]"
      ],
      "metadata": {
        "id": "1mUqe6U2K2aQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "client = genai.Client(api_key=GEMINI_API_KEY)\n",
        "chat = client.chats.create(\n",
        "    model = \"gemini-1.5-flash\",\n",
        "    config = {\n",
        "        \"tools\": operation_tools,\n",
        "        \"automatic_function_calling\": {\"disable\": False} # This line is not needed as automatic_function_calling is enabled by default\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "MzewYmHqLBfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.send_message(\n",
        "    \"I have 57 cats, each owns 44 mittens, how many mittens is that in total?\"\n",
        ")\n",
        "response.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9AE07K9gLc2a",
        "outputId": "88040ee1-c728-4a11-9b3b-9f68b7fad8e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'57 cats * 44 mittens/cat = 2508 mittens.  There are a total of 2508 mittens.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown, display\n",
        "\n",
        "for content in chat.get_history():\n",
        "    display(Markdown(\"###\" + content.role + \":\"))\n",
        "    for part in content.parts:\n",
        "        if part.text:\n",
        "            display(Markdown(part.text))\n",
        "        if part.function_call:\n",
        "            print(\"Function call: {\", part.function_call, \"}\")\n",
        "        if part.function_response:\n",
        "            print(\"Function response: {\", part.function_response, \"}\")\n",
        "    print(\"-\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "Nh-FlRHXLigX",
        "outputId": "43f9936a-a4d2-4715-883c-59d75a584f12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###user:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "I have 57 cats, each owns 44 mittens, how many mittens is that in total?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###model:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function call: { id=None args={'b': 44, 'a': 57} name='multiply' }\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###user:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function response: { id=None name='multiply' response={'result': 2508} }\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###model:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "57 cats * 44 mittens/cat = 2508 mittens.  There are a total of 2508 mittens.\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_light_values(brightness: int, color_temp: str) -> dict[str, int | str]:\n",
        "    \"\"\"Set the brightness and color temperature of a room light. (mock API).\n",
        "\n",
        "    Args:\n",
        "        brightness: Light level from 0 to 100. Zero is off and 100 is full brightness\n",
        "        color_temp: Color temperature of the light fixture, which can be `daylight`, `cool` or `warm`.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing the set brightness and color temperature.\n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"brightness\": brightness,\n",
        "        \"colorTemperature\": color_temp\n",
        "    }"
      ],
      "metadata": {
        "id": "6BraKl4pLzfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.genai import types\n",
        "\n",
        "config = types.GenerateContentConfig(tools=[set_light_values])"
      ],
      "metadata": {
        "id": "9Gr7Kux0L3LW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "client = genai.Client(api_key=GEMINI_API_KEY)\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model='gemini-2.0-flash',\n",
        "    config=config,\n",
        "    contents='Turn the lights down to a movie watching level'\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiA6ZJFoL8px",
        "outputId": "faf17315-e2c1-43f2-fd58-2c3ec401252b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What brightness level would you consider appropriate for watching a movie? \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViSVW3ixMho7",
        "outputId": "6d870688-7301-4ff3-e47b-e1c6e46142b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GenerateContentResponse(candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='What brightness level would you like to set for watching a movie?')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.34281209798959583, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)], create_time=None, response_id=None, model_version='gemini-2.0-flash', prompt_feedback=None, usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=13, prompt_token_count=107, total_token_count=120), automatic_function_calling_history=[], parsed=None)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the chat interface\n",
        "chat = client.chats.create(model='gemini-2.0-flash', config=config)\n",
        "response = chat.send_message('Turn the lights down to a movie watching level')\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnAXjWwxMHsC",
        "outputId": "973a1506-4255-41fc-9797-9104a3a8dc4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What brightness level would you like to set for watching a movie?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Latihan"
      ],
      "metadata": {
        "id": "0BNDU0xedtcH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sekarang cobalah lakukan latihan untuk menerapkan beberapa teknik prompting serta dengan konfigurasi temperature, top_k dan top_p yang berbeda-beda."
      ],
      "metadata": {
        "id": "NMn8jas8dhgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "prompt_sentiment_analysis = \"\"\"\n",
        "Anda adalah AI yang menganalisis sentimen teks\n",
        "Klasifikasikan teks ke dalam salah satu kategori berikut:\n",
        "- Positif\n",
        "- Negatif\n",
        "- Netral\n",
        "\n",
        "Berikan juga penjelasan singkat mengapa teks diklasifikasikan ke dalam kategori tersebut.\n",
        "\"\"\"\n",
        "\n",
        "model=genai.GenerativeModel(\n",
        "  model_name=\"gemini-1.5-flash\",\n",
        "  system_instruction=prompt_sentiment_analysis\n",
        "  )\n",
        "\n",
        "question = \"besok ada acara di desa\"\n",
        "response = model.generate_content(\n",
        "    question,\n",
        "    generation_config=genai.types.GenerationConfig(\n",
        "        max_output_tokens=200,\n",
        "        temperature=1.0,\n",
        "        top_k=5,\n",
        "        top_p=1.0,\n",
        "    ),\n",
        "  )\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "6mncYO2MMTTD",
        "outputId": "df214cd5-f211-4ce3-e020-5ae1a2da5653"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Netral.\n\nTeks tersebut hanya menyatakan fakta adanya acara di desa besok, tanpa mengungkapkan sentimen positif maupun negatif.  Tidak ada kata-kata atau frasa yang menunjukkan emosi atau penilaian terhadap acara tersebut.\n"
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XXPrsL98Pj1w"
      }
    }
  ]
}